{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'UNCOMPRESSED'\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "def subtract_one_label(text, label):\n",
    "    return text, label - 1\n",
    "\n",
    "train_df = pd.read_csv('./dataset/train.csv')\n",
    "val_df = pd.read_csv('./dataset/test.csv')\n",
    "\n",
    "text_col = 'description'\n",
    "label_col = 'label'\n",
    "\n",
    "# print(train_df.iloc[:1]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get the slices of an array in the form of objects by using tf.data.Dataset.from_tensor_slices() method.\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_df[text_col].values, train_df[label_col].values))\n",
    "train_data = train_data.map(subtract_one_label)\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((val_df[text_col].values, val_df[label_col].values))\n",
    "val_data = val_data.map(subtract_one_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The news are grouped into 4 classes that are :['World', 'Sports', 'Business', 'Sci/Tech']\n",
      "The number of training samples: 120000 \n",
      "The number of validation samples: 7600\n"
     ]
    }
   ],
   "source": [
    "class_names = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "num_classes = len(class_names)\n",
    "num_train = len(train_df)\n",
    "num_val = len(val_df)\n",
    "\n",
    "print(f'The news are grouped into {num_classes} classes that are :{class_names}')\n",
    "print(f'The number of training samples: {num_train} \\nThe number of validation samples: {num_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample news 0\n",
      "     Label: 2 Business\n",
      "     Description: Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "----------\n",
      "\n",
      "Sample news 1\n",
      "     Label: 2 Business\n",
      "     Description: Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\n",
      "----------\n",
      "\n",
      "Sample news 2\n",
      "     Label: 2 Business\n",
      "     Description: Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
      "----------\n",
      "\n",
      "Sample news 3\n",
      "     Label: 2 Business\n",
      "     Description: Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (text, label) in enumerate(train_data.take(4)):\n",
    "    print(f\"Sample news {i}\\n \\\n",
    "    Label: {label.numpy()} {class_names[label.numpy()]}\\n \\\n",
    "    Description: {text.numpy().decode('utf-8')}\\n----------\\n\")\n",
    "\n",
    "buffer_size = 1000\n",
    "batch_size = 32\n",
    "\n",
    "train_data = train_data.shuffle(buffer_size)\n",
    "train_data = train_data.batch(batch_size).prefetch(1)\n",
    "val_data = val_data.batch(batch_size).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample news\n",
      "----\n",
      " [b\"The new APMF survey of the best Asian tourism destinations has just kicked off, but it's crowded at the top, with Chiang Mai in Thailand just leading from perennial favourites Hong Kong, Bangkok and Phuket in Thailand, and Bali in  Indonesia. Be one of the first to vote and let us know your reasons.\"\n",
      " b\"At 23, pitcher Richard Stahl knows there's still time to impress the Baltimore Orioles' front office. He just needs to stay on the mound long enough.\"\n",
      " b'The first request by British scientists to clone human embryos has been granted by experts.'\n",
      " b'\"Jam band\" Phish play their last gigs together at a special festival in the US which has attracted thousands of fans.'] \n",
      "----\n",
      "Corresponding labels: [2 1 3 0]\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "File system scheme 'gs' not implemented (file: 'gs://tfhub-modules/tensorflow/bert_en_uncased_preprocess/3/uncompressed')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\github\\post-training-deep-learning\\Subco_2\\Session 04. Word Embeddings\\Session 04. Word Embeddings\\text-classification-using-bert.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/post-training-deep-learning/Subco_2/Session%2004.%20Word%20Embeddings/Session%2004.%20Word%20Embeddings/text-classification-using-bert.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m bert_handle \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/2\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/post-training-deep-learning/Subco_2/Session%2004.%20Word%20Embeddings/Session%2004.%20Word%20Embeddings/text-classification-using-bert.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m preprocessing_model \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/github/post-training-deep-learning/Subco_2/Session%2004.%20Word%20Embeddings/Session%2004.%20Word%20Embeddings/text-classification-using-bert.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m preprocess_layer \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mKerasLayer(preprocessing_model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/post-training-deep-learning/Subco_2/Session%2004.%20Word%20Embeddings/Session%2004.%20Word%20Embeddings/text-classification-using-bert.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m sample_news \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mTech rumors: The tech giant Apple is working on its self driving car\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/post-training-deep-learning/Subco_2/Session%2004.%20Word%20Embeddings/Session%2004.%20Word%20Embeddings/text-classification-using-bert.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m preprocessed_news \u001b[39m=\u001b[39m preprocess_layer(sample_news)\n",
      "File \u001b[1;32mc:\\Users\\TinTin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:157\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_shape \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39mNoDependency(\n\u001b[0;32m    154\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func \u001b[39m=\u001b[39m load_module(handle, tags, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_options)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, \u001b[39m\"\u001b[39m\u001b[39m_is_hub_module_v1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[39m# Update with the defaults when using legacy TF1 Hub format.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TinTin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:459\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m       set_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m module_v2\u001b[39m.\u001b[39;49mload(handle, tags\u001b[39m=\u001b[39;49mtags, options\u001b[39m=\u001b[39;49mset_load_options)\n",
      "File \u001b[1;32mc:\\Users\\TinTin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:93\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m     92\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected a string, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m handle)\n\u001b[1;32m---> 93\u001b[0m module_path \u001b[39m=\u001b[39m resolve(handle)\n\u001b[0;32m     94\u001b[0m is_hub_module_v1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(\n\u001b[0;32m     95\u001b[0m     native_module\u001b[39m.\u001b[39mget_module_proto_path(module_path))\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m tags \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m is_hub_module_v1:\n",
      "File \u001b[1;32mc:\\Users\\TinTin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:48\u001b[0m, in \u001b[0;36mresolve\u001b[1;34m(handle)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresolve\u001b[39m(handle):\n\u001b[0;32m     25\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Resolves a module handle into a path.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[39m  This function works both for plain TF2 SavedModels and the legacy TF1 Hub\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39m    A string representing the Module path.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m   \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39;49mresolver(handle)\n",
      "File \u001b[1;32mc:\\Users\\TinTin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\registry.py:49\u001b[0m, in \u001b[0;36mMultiImplRegister.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mfor\u001b[39;00m impl \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impls):\n\u001b[0;32m     48\u001b[0m   \u001b[39mif\u001b[39;00m impl\u001b[39m.\u001b[39mis_supported(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     fails\u001b[39m.\u001b[39mappend(\u001b[39mtype\u001b[39m(impl)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\TinTin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\uncompressed_module_resolver.py:34\u001b[0m, in \u001b[0;36mHttpUncompressedFileResolver.__call__\u001b[1;34m(self, handle)\u001b[0m\n\u001b[0;32m     32\u001b[0m handle_with_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_uncompressed_format_query(handle)\n\u001b[0;32m     33\u001b[0m gcs_location \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request_gcs_location(handle_with_params)\n\u001b[1;32m---> 34\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath_resolver(gcs_location)\n",
      "File \u001b[1;32mc:\\Users\\TinTin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:498\u001b[0m, in \u001b[0;36mPathResolver.__call__\u001b[1;34m(self, handle)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, handle):\n\u001b[1;32m--> 498\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mgfile\u001b[39m.\u001b[39;49mExists(handle):\n\u001b[0;32m    499\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m does not exist.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m handle)\n\u001b[0;32m    500\u001b[0m   \u001b[39mreturn\u001b[39;00m handle\n",
      "File \u001b[1;32mc:\\Users\\TinTin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:296\u001b[0m, in \u001b[0;36mfile_exists\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mgfile.Exists\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    295\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfile_exists\u001b[39m(filename):\n\u001b[1;32m--> 296\u001b[0m   \u001b[39mreturn\u001b[39;00m file_exists_v2(filename)\n",
      "File \u001b[1;32mc:\\Users\\TinTin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:288\u001b[0m, in \u001b[0;36mfile_exists_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determines whether a path exists or not.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \n\u001b[0;32m    251\u001b[0m \u001b[39m>>> with open(\"/tmp/x\", \"w\") as f:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m  errors.OpError: Propagates any errors reported by the FileSystem API.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m   _pywrap_file_io\u001b[39m.\u001b[39;49mFileExists(compat\u001b[39m.\u001b[39;49mpath_to_bytes(path))\n\u001b[0;32m    289\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError:\n\u001b[0;32m    290\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: File system scheme 'gs' not implemented (file: 'gs://tfhub-modules/tensorflow/bert_en_uncased_preprocess/3/uncompressed')"
     ]
    }
   ],
   "source": [
    "for news, label in train_data.take(1):\n",
    "    print(f'Sample news\\n----\\n {news.numpy()[:4]} \\n----\\nCorresponding labels: {label.numpy()[:4]}')\n",
    "  \n",
    "bert_handle = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/2'\n",
    "preprocessing_model = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "preprocess_layer = hub.KerasLayer(preprocessing_model)\n",
    "\n",
    "sample_news = ['Tech rumors: The tech giant Apple is working on its self driving car']\n",
    "preprocessed_news = preprocess_layer(sample_news)\n",
    "\n",
    "print(f'Keys       : {list(preprocessed_news.keys())}')\n",
    "print(f'Shape      : {preprocessed_news[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {preprocessed_news[\"input_word_ids\"][0, :5]}')\n",
    "print(f'Input Mask : {preprocessed_news[\"input_mask\"][0, :5]}')\n",
    "print(f'Type Ids   : {preprocessed_news[\"input_type_ids\"][0, :5]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(bert_handle)\n",
    "bert_outputs = bert_model(preprocessed_news)\n",
    "\n",
    "print(f'Pooled output shape:{bert_outputs[\"pooled_output\"].shape}')\n",
    "print(f'Pooled output values:{bert_outputs[\"pooled_output\"][0, :5]}')\n",
    "print(f'Sequence output shape:{bert_outputs[\"sequence_output\"].shape}')\n",
    "print(f'Sequence output values:{bert_outputs[\"sequence_output\"][0, :5]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = tf.keras.layers.Input(shape=(), dtype=tf.string, name='Input')\n",
    "\n",
    "# A preprocesing model before layer BERT\n",
    "preprocessing_layer = hub.KerasLayer(preprocessing_model, name='preprocessing_layer')\n",
    "bert_input = preprocessing_layer(input_text)\n",
    "\n",
    "# Getting a Bert model, set trainable to True\n",
    "bert_encoder = hub.KerasLayer(bert_handle, trainable=True, name='bert_encoder')\n",
    "bert_outputs = bert_encoder(bert_input)\n",
    "\n",
    "# For finetuning, we take pooled_output\n",
    "pooled_bert_output = bert_outputs['pooled_output']\n",
    "\n",
    "# Adding a dense layer \n",
    "dense_net = tf.keras.layers.Dense(16, activation='relu', name='fully_connected_layer')(pooled_bert_output)\n",
    "\n",
    "# Add dropout layer for regularization\n",
    "dense_net = tf.keras.layers.Dropout(0.2)(dense_net)\n",
    "\n",
    "# Last dense layer for classification purpose\n",
    "final_output = tf.keras.layers.Dense(4, activation='softmax', name='classifier')(dense_net)\n",
    "\n",
    "# Combine input and output\n",
    "news_classifier = tf.keras.Model(input_text, final_output)\n",
    "\n",
    "print(news_classifier.summary())\n",
    "\n",
    "news_classifier.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5), \n",
    "                        loss='sparse_categorical_crossentropy', \n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "\n",
    "# Compute the length of the train_data and val_data\n",
    "num_train = sum(1 for _ in train_data)\n",
    "num_val = sum(1 for _ in val_data)\n",
    "\n",
    "train_steps = num_train // batch_size\n",
    "val_steps = num_val // batch_size\n",
    "\n",
    "history = news_classifier.fit(train_data, epochs=15, validation_data=val_data, steps_per_epoch=train_steps, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot accuracy and loss\n",
    "def plot_acc_loss(history):\n",
    "    model_history = history.history\n",
    "    acc = model_history['accuracy']\n",
    "    val_acc = model_history['val_accuracy']\n",
    "    loss = model_history['loss']\n",
    "    val_loss = model_history['val_loss']\n",
    "    \n",
    "    epochs = history.epoch\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'g', label='Validation Accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(\"Training and Validation Accuracy.png\")\n",
    "    plt.legend(loc=0)\n",
    "\n",
    "    # Create a new figure with plt.figure()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'y', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=0)\n",
    "    plt.savefig(\"Training and Validation Loss.png\")\n",
    "    plt.show()\n",
    "  \n",
    "plot_acc_loss(history)\n",
    "\n",
    "def predict(model, sample_news, class_names):\n",
    "    # Convert sample news into array\n",
    "    sample_news = np.array(sample_news)\n",
    "\n",
    "    # Predict the news type\n",
    "    preds = model.predict(sample_news)\n",
    "    pred_class = np.argmax(preds[0])\n",
    "\n",
    "    print(f'predicted class: {pred_class} \\nPredicted Class name: {class_names[pred_class]}')\n",
    "\n",
    "sample_news = ['Tesla, a self driving car company is also planning to make a humanoid robot. This humanoid robot appeared dancing in the latest Tesla AI day']\n",
    "predict(news_classifier, sample_news, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
